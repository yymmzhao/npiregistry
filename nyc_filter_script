# filter nyc data by zip codes from the data directly downloaded from NPPES
# process data by chunks, with 50K per chunk
# save the output file with .csv, not .xlsx
---
import pandas as pd
import os

# Define NYC borough ZIP codes
manhattan_zips = ['10001', '10002', '10003', '10004', '10005', '10006', '10007', '10008', '10009', '10010', 
                 '10011', '10012', '10013', '10014', '10016', '10017', '10018', '10019', '10020', '10021', 
                 '10022', '10023', '10024', '10025', '10026', '10027', '10028', '10029', '10030', '10031', 
                 '10032', '10033', '10034', '10035', '10036', '10037', '10038', '10039', '10040', '10044', 
                 '10065', '10069', '10075', '10101', '10104', '10105', '10106', '10107', '10108', '10111', 
                 '10112', '10113', '10116', '10118', '10119', '10128', '10129', '10150', '10151', '10153', 
                 '10156', '10159', '10162', '10163', '10165', '10168', '10169', '10170', '10174', '10175', 
                 '10176', '10178', '10185', '10268', '10272', '10274', '10276', '10280', '10282', '10708', '10979']

brooklyn_zips = ['11201', '11202', '11203', '11204', '11205', '11206', '11207', '11208', 
                '11209', '11210', '11211', '11212', '11213', '11214', '11215', '11216', 
                '11217', '11218', '11219', '11220', '11221', '11222', '11223', '11224', 
                '11225', '11226', '11228', '11229', '11230', '11231', '11232', '11233', 
                '11234', '11235', '11236', '11237', '11238', '11239', '11247', '11249']

queens_zips = ['11101', '11102', '11103', '11105', '11106', '11109', '11352', '11354', 
              '11355', '11358', '11360', '11361', '11367', '11368', '11369', '11370', 
              '11371', '11372', '11373', '11375', '11377', '11380', '11416', '11417', 
              '11424', '11427', '11428', '11429', '11430', '11431', '11432', '11433', '11434', '11435']

bronx_zips = ['10451', '10452', '10453', '10454', '10455', '10456', '10457', '10458', 
             '10459', '10460', '10461', '10462', '10463', '10464', '10465', '10466', 
             '10467', '10468', '10469', '10470', '10471', '10472', '10473', '10474', '10475']

staten_island_zips = ['10301', '10302', '10303', '10304', '10305', '10306', '10307', 
                     '10308', '10309', '10310', '10312', '10313', '10314']

# Combine all NYC ZIP codes
all_nyc_zips = set(manhattan_zips + brooklyn_zips + queens_zips + bronx_zips + staten_island_zips)

def extract_first_5_digits(zip_code):
    """Extract first 5 digits from ZIP code, handling various formats"""
    if pd.isna(zip_code):
        return None
    zip_str = str(zip_code).strip()
    return zip_str[:5]

def filter_nyc_providers_to_csv(input_file_path, output_file_path, chunk_size=50000):
    """Filter NPI data for NYC providers and save to CSV (much faster than Excel)"""
    
    print("Processing NPI data in chunks and saving to CSV...")
    
    # Initialize counters
    total_records = 0
    nyc_records = 0
    chunk_number = 0
    first_chunk = True
    
    # Process file in chunks and write directly to CSV
    chunk_reader = pd.read_csv(input_file_path, dtype=str, low_memory=False, chunksize=chunk_size)
    
    for chunk in chunk_reader:
        chunk_number += 1
        chunk_size_actual = len(chunk)
        total_records += chunk_size_actual
        
        print(f"Processing chunk {chunk_number}: {chunk_size_actual:,} records (Total processed: {total_records:,})")
        
        # Extract first 5 digits from ZIP codes
        chunk['Mailing_ZIP5'] = chunk['Provider Business Mailing Address Postal Code'].apply(extract_first_5_digits)
        chunk['Practice_ZIP5'] = chunk['Provider Business Practice Location Address Postal Code'].apply(extract_first_5_digits)
        
        # Filter for NYC ZIP codes
        nyc_filter = (
            chunk['Mailing_ZIP5'].isin(all_nyc_zips) | 
            chunk['Practice_ZIP5'].isin(all_nyc_zips)
        )
        
        # Apply filter
        nyc_chunk = chunk[nyc_filter].copy()
        
        # Drop the temporary ZIP5 columns
        nyc_chunk = nyc_chunk.drop(['Mailing_ZIP5', 'Practice_ZIP5'], axis=1)
        
        chunk_nyc_count = len(nyc_chunk)
        nyc_records += chunk_nyc_count
        
        print(f"  Found {chunk_nyc_count:,} NYC records in this chunk (Total NYC so far: {nyc_records:,})")
        
        # Write NYC records from this chunk directly to CSV
        if chunk_nyc_count > 0:
            if first_chunk:
                # Create new CSV file with headers
                nyc_chunk.to_csv(output_file_path, index=False, mode='w')
                first_chunk = False
                print(f"  Created CSV file: {output_file_path}")
            else:
                # Append to existing CSV file
                nyc_chunk.to_csv(output_file_path, index=False, mode='a', header=False)
                print(f"  Appended {chunk_nyc_count:,} records to CSV")
    
    print(f"\nProcessing complete!")
    print(f"Total chunks processed: {chunk_number}")
    print(f"Total records processed: {total_records:,}")
    print(f"NYC records found: {nyc_records:,}")
    print(f"Percentage of records in NYC: {(nyc_records / total_records * 100):.2f}%")
    print(f"CSV file saved to: {output_file_path}")
    
    return nyc_records, total_records

# Main execution
if __name__ == "__main__":
    # File paths
    input_file = r"C:/Users/Yueming Zhao/Desktop/Multidisciplinary IEP-Related Evaluations/NPI/npidata_pfile_20050523-20251109.csv"
    
    # Save as CSV for much faster processing
    output_file = r"C:/Users/Yueming Zhao/Desktop/Multidisciplinary IEP-Related Evaluations/NPI/npi_nyc.csv"
    
    # Check if input file exists
    if not os.path.exists(input_file):
        print(f"Error: Input file not found at {input_file}")
        print("Please verify the file path is correct.")
    else:
        # Create output directory if it doesn't exist
        output_dir = os.path.dirname(output_file)
        if output_dir and not os.path.exists(output_dir):
            try:
                os.makedirs(output_dir, exist_ok=True)
                print(f"Created output directory: {output_dir}")
            except Exception as e:
                print(f"Could not create output directory: {e}")
                print("Saving to current directory instead...")
                output_file = "npi_nyc.csv"
        
        # Filter the data using chunked processing
        nyc_count, total_count = filter_nyc_providers_to_csv(input_file, output_file, chunk_size=50000)
        
        print(f"\n--- Final Summary ---")
        print(f"Total records processed: {total_count:,}")
        print(f"NYC records found: {nyc_count:,}")
        print(f"NYC percentage: {(nyc_count / total_count * 100):.2f}%")
        print(f"Output file: {output_file}")
        
        # Optional: Display sample of final filtered data
        if nyc_count > 0:
            print("\n--- Sample of filtered data ---")
            try:
                sample_data = pd.read_csv(output_file, nrows=5)
                print(sample_data.head())
            except Exception as e:
                print(f"Could not read sample data: {e}")
        
        print("\nTo convert CSV to Excel later (if needed):")
        print("df = pd.read_csv('npi_nyc.csv')")
        print("df.to_excel('npi_nyc.xlsx', index=False)")
